{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940d26c3",
   "metadata": {},
   "source": [
    "## VQE ansatz: 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42055090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from wordsToNumbers import Corpus\n",
    "from wordsToNumbers import fibonacci_vocabulary\n",
    "\n",
    "from wordsToQubits import put_word_on_sphere\n",
    "\n",
    "from utils import get_corpus_from_directory, working_window, get_word_from_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25724fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a727b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4951bf91",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1bc2987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr. words:1648 \n",
      "nr. distinct words: 499 \n",
      "len.text/len.vocab:3.302605210420842\n"
     ]
    }
   ],
   "source": [
    "corpus_path='/Users/voicutu/Desktop/Qountry/CountryMixt'\n",
    "\n",
    "corpus_tex = get_corpus_from_directory(corpus_path, limit=1)\n",
    "\n",
    "corpus= Corpus(corpus_tex)\n",
    "print(corpus.prop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a79b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterize_vovabulary = fibonacci_vocabulary(corpus.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3761a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: ['same', 'old', 'dive', 'same', 'old', 'end', 'of', 'the', 'work', 'week', 'drink', 'bartender', 'knows', 'my', 'name', 'but', 'i', 'dont', 'mind', 'she', 'kicks', 'em', 'up', 'strong', 'serves', 'me', 'up', 'right', 'and', 'here', 'i', 'go', 'again', 'im', 'drinkin', 'one', 'im', 'drinkin', 'two', 'i', 'got', 'my', 'heartache', 'medication', 'a', 'strong', 'dedication', 'to', 'gettin', 'over', 'you', 'turnin', 'me', 'loose', 'on', 'that', 'hardwood', 'jukebox', 'lost', 'in', 'neon', 'time', 'my', 'heartache', 'medication', 'well', 'it', 'suits', 'me', 'fine', 'and', 'im', 'drinkin', 'enough', 'to', 'take', 'you', 'off', 'my', 'mind', 'i', 'got', 'my', 'heartache', 'medication', 'well', 'in', 'my', 'time', 'of', 'dying', 'dont', 'want', 'nobody', 'to', 'mourn', 'all', 'i', 'want', 'for', 'you', 'to', 'do', 'is', 'take', 'my', 'body', 'home', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'well', 'well', 'well', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'my', 'dying', 'bed', 'well', 'meet', 'me', 'jesus', 'meet', 'me', 'meet', 'me', 'in', 'the', 'middle', 'of', 'the', 'air', 'if', 'these', 'wings', 'should', 'fail', 'to', 'me', 'lord', 'wont', 'you', 'meet', 'me', 'with', 'another', 'pair', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'well', 'well', 'well', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'my', 'dying', 'bed', 'lord', 'in', 'my', 'time', 'of', 'dying', 'dont', 'want', 'nobody', 'to', 'cry', 'all', 'i', 'want', 'you', 'to', 'do', 'is', 'take', 'me', 'when', 'i', 'die', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'well', 'well', 'well', 'well', 'well', 'well', 'so', 'i', 'can', 'die', 'easy', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'jesus', 'gonna', 'make', 'up', 'my', 'dying', 'bed', 'put', 'on', 'my', 'jeans', 'my', 'favorite', 'shirt', 'pull', 'up', 'my', 'boots', 'and', 'hit', 'the', 'dirt', 'finally', 'doin', 'somethin', 'ive', 'dreamed', 'of', 'for', 'years', 'dont', 'know', 'quite', 'what', 'to', 'expect', 'a', 'little', 'scared', 'but', 'what', 'the', 'heck', 'my', 'desire', 'is', 'always', 'greater', 'than', 'my', 'fear', 'big', 'dreams', 'and', 'faded', 'jeans', 'fit', 'together', 'like', 'a', 'team', 'always', 'busting', 'at', 'the', 'seams', 'big', 'dreams', 'and', 'faded', 'jeans', 'just', 'my', 'ole', 'guitar', 'and', 'me', 'out', 'to', 'find', 'my', 'destiny', 'nashville', 'is', 'the', 'place', 'to', 'be', 'for', 'big', 'dreams', 'and', 'faded', 'jeans', 'put', 'out', 'my', 'thumb', 'and', 'wish', 'for', 'luck', 'to', 'hitch', 'a', 'car', 'a', 'semitruck', 'sooner', 'or', 'later', 'one', 'will', 'catch', 'me', 'in', 'their', 'beams', 'then', 'ill', 'be', 'on', 'my', 'way', 'at', 'last', 'find', 'a', 'future', 'lose', 'a', 'past', 'waiting', 'silent', 'as', 'the', 'passion', 'in', 'me', 'screams', 'big', 'dreams', 'and', 'faded', 'jeans', 'fit', 'together', 'like', 'a', 'team', 'always', 'busting', 'at', 'the', 'seams', 'big', 'dreams', 'and', 'faded', 'jeans', 'may', 'the', 'stars', 'that', 'fill', 'my', 'eyes', 'guide', 'my', 'path', 'and', 'be', 'my', 'light', 'and', 'may', 'god', 'provide', 'the', 'means', 'to', 'accomplish', 'my', 'big', 'dreams', 'my', 'big', 'dreams', 'big', 'dreams', 'and', 'faded', 'jeans', 'fit', 'together', 'like', 'a', 'team', 'always', 'busting', 'at', 'the', 'seams', 'big', 'dreams', 'and', 'faded', 'jeans', 'like', 'the', 'song', 'bobby', 'mcgee', 'freedoms', 'just', 'another', 'word', 'im', 'just', 'longin', 'to', 'be', 'free', 'to', 'be', 'free', 'take', 'me', 'where', 'i', 'want', 'to', 'be', 'big', 'dreams', 'and', 'faded', 'jeans', 'and', 'there', 'are', 'many', 'just', 'like', 'me', 'with', 'big', 'dreams', 'and', 'faded', 'jeans', 'mmhmmmmmm', 'mmhmmmmmm', 'big', 'dreams', 'big', 'dreams', 'and', 'faded', 'jeans', 'ohohohoh', 'ohohohoh', 'im', 'just', 'longing', 'to', 'be', 'free', 'take', 'me', 'where', 'i', 'want', 'to', 'be', 'big', 'dreams', 'and', 'faded', 'jeans', 'well', 'i', 'dont', 'know', 'why', 'i', 'love', 'you', 'like', 'i', 'do', 'nobody', 'in', 'the', 'world', 'can', 'get', 'along', 'with', 'you', 'you', 'got', 'the', 'ways', 'of', 'a', 'devil', 'sleeping', 'in', 'a', 'lions', 'den', 'i', 'come', 'home', 'last', 'night', 'you', 'wouldnt', 'even', 'let', 'me', 'in', 'well', 'sometimes', 'youre', 'as', 'sweet', 'as', 'anybody', 'want', 'to', 'be', 'when', 'you', 'get', 'a', 'crazy', 'notion', 'of', 'jumpin', 'all', 'over', 'me', 'well', 'you', 'give', 'me', 'the', 'blues', 'i', 'guess', 'youre', 'satisfied', 'an', 'you', 'give', 'me', 'the', 'blues', 'i', 'wanna', 'lay', 'down', 'and', 'die', 'i', 'helped', 'you', 'when', 'you', 'had', 'no', 'shoes', 'on', 'your', 'feet', 'pretty', 'mama', 'i', 'helped', 'you', 'when', 'you', 'had', 'no', 'food', 'to', 'eat', 'youre', 'the', 'kind', 'of', 'woman', 'i', 'just', 'dont', 'understand', 'youre', 'takin', 'all', 'my', 'money', 'and', 'give', 'it', 'to', 'another', 'man', 'well', 'youre', 'the', 'kinda', 'woman', 'makes', 'a', 'man', 'lose', 'his', 'brain', 'youre', 'the', 'kinda', 'woman', 'drives', 'a', 'man', 'insane', 'you', 'give', 'me', 'the', 'blues', 'i', 'guess', 'youre', 'satisfied', 'you', 'give', 'me', 'the', 'blues', 'i', 'wanna', 'lay', 'down', 'and', 'die', 'well', 'you', 'give', 'me', 'the', 'blues', 'i', 'wanna', 'lay', 'down', 'and', 'die', 'i', 'am', 'a', 'man', 'of', 'constant', 'sorrow', 'ive', 'seen', 'trouble', 'all', 'my', 'days', 'ill', 'say', 'goodbye', 'to', 'colorado', 'where', 'i', 'was', 'born', 'and', 'partly', 'raised', 'your', 'mother', 'says', 'that', 'im', 'a', 'stranger', 'a', 'face', 'youll', 'never', 'see', 'no', 'more', 'but', 'heres', 'one', 'promise', 'to', 'ya', 'ill', 'see', 'you', 'on', 'gods', 'golden', 'shore', 'through', 'this', 'open', 'world', 'im', 'abound', 'to', 'ramble', 'through', 'ice', 'and', 'snow', 'sleet', 'and', 'rain', 'im', 'abound', 'to', 'ride', 'that', 'mornin', 'railroad', 'perhaps', 'ill', 'die', 'upon', 'that', 'train', 'im', 'agoin', 'back', 'to', 'colorado', 'the', 'place', 'that', 'ive', 'started', 'from', 'if', 'id', 'knowed', 'how', 'bad', 'youd', 'treat', 'me', 'babe', 'i', 'never', 'would', 'have', 'come', 'ive', 'been', 'around', 'this', 'whole', 'country', 'but', 'i', 'never', 'yet', 'found', 'fenneario', 'well', 'as', 'we', 'marched', 'down', 'as', 'we', 'marched', 'down', 'well', 'as', 'we', 'marched', 'down', 'to', 'fennerio', 'well', 'our', 'captain', 'fell', 'in', 'love', 'with', 'a', 'lady', 'like', 'a', 'dove', 'her', 'name', 'that', 'she', 'had', 'was', 'pretty', 'peggyo', 'well', 'what', 'will', 'your', 'mother', 'say', 'what', 'will', 'your', 'mother', 'say', 'what', 'will', 'your', 'mother', 'say', 'pretty', 'peggyo', 'what', 'will', 'your', 'mother', 'say', 'to', 'know', 'youre', 'going', 'away', 'youre', 'never', 'never', 'never', 'coming', 'backio', 'come', 'arunning', 'down', 'your', 'stairs', 'come', 'arunning', 'down', 'your', 'stairs', 'come', 'arunning', 'down', 'your', 'stairs', 'pretty', 'peggyo', 'come', 'arunning', 'down', 'your', 'stairs', 'combing', 'back', 'your', 'yellow', 'hair', 'youre', 'the', 'prettiest', 'darned', 'girl', 'i', 'ever', 'seenio', 'the', 'lieutenant', 'he', 'has', 'gone', 'the', 'lieutenant', 'he', 'has', 'gone', 'the', 'lieutenant', 'he', 'has', 'gone', 'pretty', 'peggyo', 'the', 'lieutenant', 'he', 'has', 'gone', 'long', 'gone', 'hes', 'ariding', 'down', 'in', 'texas', 'with', 'the', 'rodeo', 'well', 'our', 'captain', 'he', 'is', 'dead', 'our', 'captain', 'he', 'is', 'dead', 'our', 'captain', 'he', 'is', 'dead', 'pretty', 'peggyo', 'well', 'our', 'captain', 'he', 'is', 'dead', 'died', 'for', 'a', 'maid', 'hes', 'buried', 'somewhere', 'in', 'louisianao', 'feeling', 'funny', 'in', 'my', 'mind', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'fixing', 'to', 'die', 'feeling', 'funny', 'in', 'my', 'mind', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'well', 'i', 'dont', 'mind', 'dying', 'but', 'i', 'hate', 'to', 'leave', 'my', 'children', 'crying', 'well', 'i', 'look', 'over', 'yonder', 'to', 'that', 'burying', 'ground', 'look', 'over', 'yonder', 'to', 'that', 'burying', 'ground', 'sure', 'seems', 'lonesome', 'lord', 'when', 'the', 'sun', 'goes', 'down', 'feeling', 'funny', 'in', 'my', 'eyes', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'fixing', 'to', 'die', 'feeling', 'funny', 'in', 'my', 'eyes', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'well', 'i', 'dont', 'mind', 'dying', 'but', 'i', 'hate', 'to', 'leave', 'my', 'children', 'crying', 'theres', 'a', 'black', 'smoke', 'rising', 'lord', 'its', 'rising', 'up', 'above', 'my', 'head', 'up', 'above', 'my', 'head', 'its', 'rising', 'up', 'above', 'my', 'head', 'up', 'above', 'my', 'head', 'and', 'tell', 'jesus', 'make', 'up', 'my', 'dying', 'bed', 'im', 'walking', 'kind', 'of', 'funny', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'fixing', 'to', 'die', 'yes', 'im', 'walking', 'kind', 'of', 'funny', 'lord', 'i', 'believe', 'im', 'fixing', 'to', 'die', 'fixing', 'to', 'die', 'fixing', 'to', 'die', 'well', 'i', 'dont', 'mind', 'dying', 'but', 'i', 'hate', 'to', 'leave', 'my', 'children', 'crying', 'ramblin', 'outa', 'the', 'wild', 'west', 'leavin', 'the', 'towns', 'i', 'love', 'the', 'best', 'thought', 'id', 'seen', 'some', 'ups', 'and', 'downs', 'til', 'i', 'come', 'into', 'new', 'york', 'town', 'people', 'goin', 'down', 'to', 'the', 'ground', 'buildings', 'goin', 'up', 'to', 'the', 'sky', 'wintertime', 'in', 'new', 'york', 'town', 'the', 'wind', 'blowin', 'snow', 'around', 'walk', 'around', 'with', 'nowhere', 'to', 'go', 'somebody', 'could', 'freeze', 'right', 'to', 'the', 'bone', 'i', 'froze', 'right', 'to', 'the', 'bone', 'new', 'york', 'times', 'said', 'it', 'was', 'the', 'coldest', 'winter', 'in', 'seventeen', 'years', 'i', 'didnt', 'feel', 'so', 'cold', 'then', 'i', 'swung', 'onto', 'my', 'old', 'guitar', 'grabbed', 'hold', 'of', 'a', 'subway', 'car', 'and', 'after', 'a', 'rocking', 'reeling', 'rolling', 'ride', 'i', 'landed', 'up', 'on', 'the', 'downtown', 'side', 'greenwich', 'village', 'i', 'walked', 'down', 'there', 'and', 'ended', 'up', 'in', 'one', 'of', 'them', 'coffeehouses', 'on', 'the', 'block', 'got', 'on', 'the', 'stage', 'to', 'sing', 'and', 'play', 'man', 'there', 'said', 'come', 'back', 'some', 'other', 'day', 'you', 'sound', 'like', 'a', 'hillbilly', 'we', 'want', 'folk', 'singers', 'here', 'well', 'i', 'got', 'a', 'harmonica', 'job', 'begun', 'to', 'play', 'blowin', 'my', 'lungs', 'out', 'for', 'a', 'dollar', 'a', 'day', 'i', 'blowed', 'inside', 'out', 'and', 'upside', 'down', 'the', 'man', 'there', 'said', 'he', 'loved', 'm', 'sound', 'he', 'was', 'ravin', 'about', 'how', 'he', 'loved', 'm', 'sound', 'dollar', 'a', 'days', 'worth', 'and', 'after', 'weeks', 'and', 'weeks', 'of', 'hangin', 'around', 'i', 'finally', 'got', 'a', 'job', 'in', 'new', 'york', 'town', 'in', 'a', 'bigger', 'place', 'bigger', 'money', 'too', 'even', 'joined', 'the', 'union', 'and', 'paid', 'm', 'dues', 'now', 'a', 'very', 'great', 'man', 'once', 'said', 'that', 'some', 'people', 'rob', 'you', 'with', 'a', 'fountain', 'pen', 'it', 'didnt', 'take', 'too', 'long', 'to', 'find', 'out', 'just', 'what', 'he', 'was', 'talkin', 'about', 'a', 'lot', 'of', 'people', 'dont', 'have', 'much', 'food', 'on', 'their', 'table', 'but', 'they', 'got', 'a', 'lot', 'of', 'forks', 'n', 'knives', 'and', 'they', 'gotta', 'cut', 'somethin', 'so', 'one', 'mornin', 'when', 'the', 'sun', 'was', 'warm', 'i', 'rambled', 'out', 'of', 'new', 'york', 'town', 'pulled', 'my', 'cap', 'down', 'over', 'my', 'eyes', 'and', 'headed', 'out', 'for', 'the', 'western', 'skies', 'so', 'long', 'new', 'york', 'howdy', 'east', 'orange', 'i', 'first', 'heard', 'this', 'from', 'ric', 'von', 'schmidt', 'he', 'lives', 'in', 'cambridge', 'ric', 'is', 'a', 'blues', 'guitar', 'player', 'i', 'met', 'him', 'one', 'day', 'on', 'the', 'green', 'pastures', 'of', 'the', 'harvard', 'university', 'baby', 'let', 'me', 'follow', 'you', 'down', 'baby', 'let', 'me', 'follow', 'you', 'down', 'well', 'ill', 'do', 'anything', 'in', 'this', 'god', 'almighty', 'world', 'if', 'you', 'just', 'let', 'me', 'follow', 'you', 'down', 'can', 'i', 'come', 'home', 'with', 'you', 'baby', 'can', 'i', 'come', 'home', 'with', 'you', 'yes', 'ill', 'do', 'anything', 'in', 'this', 'god', 'almighty', 'world', 'if', 'you', 'just', 'let', 'me', 'come', 'home', 'with', 'you', 'baby', 'let', 'me', 'follow', 'you', 'down', 'baby', 'let', 'me', 'follow', 'you', 'down', 'well', 'ill', 'do', 'anything', 'in', 'this', 'god', 'almighty', 'world', 'if', 'you', 'just', 'let', 'me', 'follow', 'you', 'down', 'yes', 'ill', 'do', 'anything', 'in', 'this', 'god', 'almighty', 'world', 'if', 'you', 'just', 'let', 'me', 'follow', 'you', 'down']\n"
     ]
    }
   ],
   "source": [
    "print(\"corpus:\",corpus.split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc7ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23056c1a",
   "metadata": {},
   "source": [
    "## Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484b6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lenghth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c733f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = working_window(history_lenghth, splited_text=corpus.split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0689e8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len training set: 1645\n"
     ]
    }
   ],
   "source": [
    "print(\"len training set:\", len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275e6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46257ec7",
   "metadata": {},
   "source": [
    "## Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58423cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=history_lenghth+1)\n",
    "\n",
    "# circuit initializer\n",
    "def circuit_initializer(words):\n",
    "    for i in range(len(words)):\n",
    "        put_word_on_sphere(words[i], qubit=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34fdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_type1(param, wires=[0,1,2]):\n",
    "\n",
    "    qml.CRZ( param[0], wires=[0,1])\n",
    "    qml.CRX( param[1], wires=[0,1])\n",
    "    qml.CRY( param[2], wires=[0,1])\n",
    "\n",
    "    qml.CRZ( param[3], wires=[1,2])\n",
    "    qml.CRX( param[4], wires=[1,2])\n",
    "    qml.CRY( param[5], wires=[1,2])\n",
    "\n",
    "    qml.CRZ( param[6], wires=[2,3])\n",
    "    qml.CRX( param[7], wires=[2,3])\n",
    "    qml.CRY( param[8], wires=[2,3])\n",
    "\n",
    "    qml.RX( param[9], wires=0)\n",
    "    qml.RY( param[10], wires=0)\n",
    "\n",
    "    qml.RX( param[11], wires=1)\n",
    "    qml.RY( param[12], wires=1)\n",
    "\n",
    "    qml.RX( param[13], wires=2)\n",
    "    qml.RY( param[14], wires=2)\n",
    "\n",
    "    qml.RX( param[15], wires=3)\n",
    "    qml.RY( param[16], wires=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a97158",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def next_gen(params, x, obs='z'):\n",
    "    \"\"\"\n",
    "    obs:'z', 'x' or 'y'\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the circuit \n",
    "    circuit_initializer(x)\n",
    "\n",
    "    # \n",
    "    for param in params:\n",
    "        layer_type1(param, wires=[0,1,2])\n",
    "    #circuit_initializer(x) # just for a test \n",
    "\n",
    "\n",
    "    # measure \n",
    "    if obs=='z':\n",
    "        return  qml.expval(qml.PauliZ(3))\n",
    "    if obs=='x':\n",
    "        return qml.expval(qml.PauliX(3))\n",
    "    if obs=='y':\n",
    "        return qml.expval(qml.PauliY(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2217ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: ['same', 'old', 'dive']\n",
      "x_vec: [[0.9784052718730347, 0.14859437751004012, -0.14367614604887163], [-0.4870840497016618, 0.7751004016064257, 0.40245309783350747], [-0.3745424134102893, -0.04417670682730934, 0.926156789712568]]\n"
     ]
    }
   ],
   "source": [
    "x_vec=[ parameterize_vovabulary[w] for w in x[0]]\n",
    "print(\"x:\",x[0])\n",
    "print(\"x_vec:\",x_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e93b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: ['same', 'old', 'dive']\n",
      "x_vec: [[0.9784052718730347, 0.14859437751004012, -0.14367614604887163], [-0.4870840497016618, 0.7751004016064257, 0.40245309783350747], [-0.3745424134102893, -0.04417670682730934, 0.926156789712568]]\n",
      "example tensor: [[0.9784052718730347, 0.14859437751004012, -0.14367614604887163], [-0.4870840497016618, 0.7751004016064257, 0.40245309783350747], [-0.3745424134102893, -0.04417670682730934, 0.926156789712568]]\n",
      "\n",
      "\n",
      "\n",
      " 0: ──RY(-4.57)──RZ(0.151)──╭C──────────╭C──────────╭C───────────RX(0.311)───RY(0.404)────────────────────────────────────────────────────────────────────────┤     \n",
      " 1: ──RY(5.13)───RZ(-1.01)──╰RZ(0.643)──╰RX(0.539)──╰RY(0.512)──╭C──────────╭C──────────╭C───────────RX(0.597)───RY(0.241)────────────────────────────────────┤     \n",
      " 2: ──RY(5.9)────RZ(0.117)──────────────────────────────────────╰RZ(0.61)───╰RX(0.493)──╰RY(0.214)──╭C──────────╭C──────────╭C──────────RX(0.906)──RY(0.159)──┤     \n",
      " 3: ────────────────────────────────────────────────────────────────────────────────────────────────╰RZ(0.244)──╰RX(0.572)──╰RY(0.773)──RX(0.589)──RY(0.262)──┤ ⟨Z⟩ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_vec=[ parameterize_vovabulary[w] for w in x[0]]\n",
    "print(\"x:\",x[0])\n",
    "print(\"x_vec:\",x_vec)\n",
    "\n",
    "params= np.random.uniform(size=(1, 17), requires_grad=True)\n",
    "\n",
    "print(\"example tensor:\", x_vec )\n",
    "print(\"\\n\\n\")\n",
    "print(qml.draw(next_gen)(params,x_vec,obs='z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d15992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vector=[ next_gen(params,x_vec, obs=o) for o in ['x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b16a4",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d76f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_target_distance(pred_vector, target):\n",
    "\n",
    "    distance= np.linalg.norm(pred_vector-target)\n",
    "\n",
    "    #np.sqrt((pred_vector[0]-target[0])*(pred_vector[0]-target[0])+\n",
    "    #                 (pred_vector[1]-target[1])*(pred_vector[1]-target[1])+\n",
    "    #                 (pred_vector[2]-target[2])*(pred_vector[2]-target[2]))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87594d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target word: same\n",
      "target vector: [0.9784052718730347, 0.14859437751004012, -0.14367614604887163]\n",
      "prediction: [tensor(0.23647916, requires_grad=True), tensor(-0.56723946, requires_grad=True), tensor(0.76346593, requires_grad=True)]\n",
      "prediction word: finally\n",
      "distance: 1.3732367572441773\n"
     ]
    }
   ],
   "source": [
    "print(\"target word:\",y[0])\n",
    "print(\"target vector:\",parameterize_vovabulary[y[0]] )\n",
    "print(\"prediction:\",pred_vector)\n",
    "pred_word= get_word_from_sphere(pred_vector, parameterize_vovabulary)\n",
    "print(\"prediction word:\",pred_word)\n",
    "distance= pred_target_distance(np.array(pred_vector), np.array(parameterize_vovabulary[y[0]]))\n",
    "print(\"distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb981b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance= pred_target_distance( np.array(parameterize_vovabulary[y[0]]) np.array(parameterize_vovabulary[y[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb9c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost( par , x, y):\n",
    "\n",
    "    predictions = [[next_gen(par, w_input,obs='x') ,next_gen(par,w_input,obs='y') ,next_gen(par,w_input,obs='z') ] for w_input in x ]\n",
    "\n",
    "    c=0.0\n",
    "    for i in range(len(predictions)):\n",
    "        c = c+ pred_target_distance(np.array(predictions[i]), y)\n",
    "\n",
    "    c=c/len(predictions)\n",
    "\n",
    "    return np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18dc8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    pred_words=[ get_word_from_sphere(p_v, parameterize_vovabulary) for p_v in predictions]\n",
    "    target_words=[ get_word_from_sphere(p_v, parameterize_vovabulary) for p_v in y]\n",
    "    ac=0\n",
    "    for i in range(len(pred_words)):\n",
    "        if pred_words[i]==target_words[i]:\n",
    "            ac=ac+1\n",
    "    return ac/len(pred_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bba265",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b071ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1642 1643 1644]\n"
     ]
    }
   ],
   "source": [
    "## shuffling data \n",
    "index = np.array([ i for i in range(len(x))])\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb08af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= []\n",
    "Y_train= []\n",
    "Y_train_w= []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    vec = [parameterize_vovabulary[w] for w in x[i]]\n",
    "    X_train.append(vec)\n",
    "    Y_train.append(parameterize_vovabulary[y[i]])\n",
    "    Y_train_w.append(y[i])\n",
    "    \n",
    "X_train= np.array(X_train)\n",
    "Y_train= np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddfa12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X,Y, batch_size):\n",
    "    X1 = [torch.reshape(x[0], (1, 2 ** (len(spec.latent_qubits) + len(spec.trash_qubits)))) for x in X]\n",
    "    X2 = []\n",
    "    for i in range(len(X1)):\n",
    "        X2.append([X1[1], X[i][1]])\n",
    "    X = X2\n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d587df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model parameters \n",
    "\n",
    "num_layers= 1\n",
    "layer_param= 17\n",
    "params = np.random.uniform(size=(2, layer_param), requires_grad=True)\n",
    "\n",
    "learning_rate= 0.6\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "nr_epochs= 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0 | train_cost:50.3107620825202\n",
      "ac: 0.0\n",
      "Iter:1 | train_cost:38.18122300977059\n",
      "Iter:2 | train_cost:26.921507477895833\n",
      "Iter:3 | train_cost:25.687757872626975\n",
      "Iter:4 | train_cost:16.232831432228924\n",
      "Iter:5 | train_cost:13.516567106917295\n",
      "Iter:6 | train_cost:11.265645195734207\n",
      "Iter:7 | train_cost:10.005262581617181\n",
      "Iter:8 | train_cost:10.183021715848525\n",
      "Iter:9 | train_cost:10.40591518327502\n",
      "Iter:10 | train_cost:8.115036040635948\n",
      "ac: 0.17264437689969606\n",
      "Iter:11 | train_cost:8.946012972897064\n",
      "Iter:12 | train_cost:8.309062237210998\n",
      "Iter:13 | train_cost:6.935274719270581\n",
      "Iter:14 | train_cost:6.217287577583877\n",
      "Iter:15 | train_cost:8.156677156941875\n",
      "Iter:16 | train_cost:3.414926255030833\n",
      "Iter:17 | train_cost:4.7235110054919565\n",
      "Iter:18 | train_cost:5.219380734756972\n",
      "Iter:19 | train_cost:3.188934140478482\n",
      "Iter:20 | train_cost:3.162451555492688\n",
      "ac: 0.05592705167173252\n",
      "Iter:21 | train_cost:4.509556364470822\n",
      "Iter:22 | train_cost:3.7437951097498017\n",
      "Iter:23 | train_cost:4.6642545899650845\n",
      "Iter:24 | train_cost:2.2870608001317096\n",
      "Iter:25 | train_cost:3.061961119333971\n",
      "Iter:26 | train_cost:5.8732916749826725\n",
      "Iter:27 | train_cost:1.9312636283177178\n",
      "Iter:28 | train_cost:10.617814373897726\n",
      "Iter:29 | train_cost:10.41505571932563\n",
      "Iter:30 | train_cost:2.0264143624575532\n",
      "ac: 0.0\n",
      "Iter:31 | train_cost:11.262601586117798\n",
      "Iter:32 | train_cost:13.172061136501755\n",
      "Iter:33 | train_cost:6.630780939455874\n",
      "Iter:34 | train_cost:6.3849216989059565\n",
      "Iter:35 | train_cost:9.978568723947177\n",
      "Iter:36 | train_cost:8.4981678621178\n",
      "Iter:37 | train_cost:3.3483653728603455\n",
      "Iter:38 | train_cost:6.216261751865879\n",
      "Iter:39 | train_cost:8.55321163176737\n",
      "Iter:40 | train_cost:6.791408210285825\n",
      "ac: 0.7975683890577507\n",
      "Iter:41 | train_cost:2.645059164221593\n",
      "Iter:42 | train_cost:4.647871351542472\n",
      "Iter:43 | train_cost:5.287192885345061\n",
      "Iter:44 | train_cost:3.2668633412770025\n",
      "Iter:45 | train_cost:4.141395862049451\n",
      "Iter:46 | train_cost:4.1343054914917285\n",
      "Iter:47 | train_cost:3.0068983299832777\n",
      "Iter:48 | train_cost:3.1243651794792826\n",
      "Iter:49 | train_cost:2.9028920342359563\n",
      "Iter:50 | train_cost:2.594347438200872\n",
      "ac: 0.5337386018237082\n",
      "Iter:51 | train_cost:3.297733148757323\n",
      "Iter:52 | train_cost:1.5889130222102026\n",
      "Iter:53 | train_cost:3.592422928087569\n",
      "Iter:54 | train_cost:2.4500954083824547\n",
      "Iter:55 | train_cost:3.2025153269583093\n",
      "Iter:56 | train_cost:3.9609194077451866\n",
      "Iter:57 | train_cost:1.957622046240156\n",
      "Iter:58 | train_cost:5.0247448085841375\n",
      "Iter:59 | train_cost:3.758987723473417\n",
      "Iter:60 | train_cost:5.537157721328497\n",
      "ac: 0.28328267477203645\n",
      "Iter:61 | train_cost:4.0884804021677414\n",
      "Iter:62 | train_cost:5.965344783745946\n",
      "Iter:63 | train_cost:5.302252250679841\n",
      "Iter:64 | train_cost:3.355300241596523\n",
      "Iter:65 | train_cost:3.719658067454865\n",
      "Iter:66 | train_cost:3.2668090952711153\n",
      "Iter:67 | train_cost:1.6077537561580324\n",
      "Iter:68 | train_cost:6.745484222892327\n",
      "Iter:69 | train_cost:6.551747990532006\n",
      "Iter:70 | train_cost:1.3979173660015731\n",
      "ac: 0.5574468085106383\n",
      "Iter:71 | train_cost:3.5046800209750333\n",
      "Iter:72 | train_cost:1.3926039190028727\n",
      "Iter:73 | train_cost:0.7583243364997493\n",
      "Iter:74 | train_cost:0.9771050436573828\n",
      "Iter:75 | train_cost:3.0252326201483135\n",
      "Iter:76 | train_cost:1.678314438492446\n",
      "Iter:77 | train_cost:1.1070874730890434\n",
      "Iter:78 | train_cost:4.342544661236135\n",
      "Iter:79 | train_cost:2.4979777945579618\n",
      "Iter:80 | train_cost:5.444235782874068\n",
      "ac: 0.0\n",
      "Iter:81 | train_cost:5.729971999079218\n",
      "Iter:82 | train_cost:1.5377094577122445\n"
     ]
    }
   ],
   "source": [
    "ls_progres=[]\n",
    "ac_progres=[]\n",
    "for e in range(nr_epochs):\n",
    "    params, ls = opt.step_and_cost(lambda p: cost( par=p, x=X_train, y=Y_train),params)\n",
    "\n",
    "    print(\"Iter:{} | train_cost:{}\".format(e, ls))\n",
    "    ls_progres.append(ls)\n",
    "\n",
    "\n",
    "    if e%10==0:\n",
    "        predictions = [[next_gen(params, w_input,obs='x') ,next_gen(params,w_input,obs='y') ,next_gen(params,w_input,obs='z') ] for w_input in X_train ]\n",
    "        ac=accuracy(predictions, y=Y_train)\n",
    "\n",
    "        print(\"ac:\",ac)\n",
    "        ac_progres.append(ac)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2be45b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032e5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
